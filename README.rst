|made-with-python| |python-version| |version|

.. |made-with-python| image:: https://img.shields.io/badge/Made%20with-Python-1f425f.svg
   :target: https://www.python.org/

.. |python-version| image:: https://img.shields.io/badge/Python-3.8.0-green.svg
   :target: https://www.python.org/

.. |version| image:: https://img.shields.io/badge/version-0.1.0-orange.svg
   :target: https://www.python.org/

=============
Global Concept-Explanations for the Self-Explaining MEGAN Graph Neural Network
=============

This package implements the functionality needed to extract global concept-based explanations from the recently published 
MEGAN (`GitHub <https://github.com/aimat-lab/graph_attention_student>`, `paper <https://link.springer.com/chapter/10.1007/978-3-031-44067-0_18>`) 
graph neural network model. The MEGAN model itself is a self-explaining graph neural network, which is able to
provide local attributional explanations its own predictions through an attention mechanism. By extending it's architecture and 
training process, it is possible to additionally extract concept explanations from it's latent space of explanation embeddings.

‚ùì What are Global Concept Explanations?
========================================

*Local* explanations aim to provide additional information about individual model predictions. Although there are different forms 
of local explanations the, the most common modality is that of importance attribution masks. For graph neural networks, these masks 
are defined on the node and edge level and usually provide a 0 to 1 *importance value* of how much a certain node or edge contributed
to the final prediction. While these explanations are very useful for understanding the model's decision making process on a case by 
case basis, it is hard to understand the model's general behavior.

*Global* explanations on the other hand aim to provide a more general understanding of the model's overal decision making process. As 
with local explanations, there exist different formats in which global model information can be presented, including generative explanations,
prototype-based explanations and concept-based explanations among others.

*Concept-based* explanations are one specific form of global explanations, which try to explain a models general behavior which is aggregated 
over many individual instances. The basic idea is to identify certain generalizable *concepts* which are then connected to a certain impact 
toward the model's prediction outcome. One such concept is generally defined as a common underlying pattern that is shared among multiple instances 
of the dataset. From a technical perspective, a concept can be defined as a set of input fragments. 

Installation
============

.. code-block:: shell

    git clone https://github.com/the16thpythonist/megan_global_explanations

Then in the main folder run a ``pip install``:

.. code-block:: shell

    cd megan_global_explanations
    python3 -m pip install .

Afterwards, you can check the install by invoking the CLI:

.. code-block:: shell

    python3 -m megan_global_explanations.cli --version
    python3 -m megan_global_explanations.cli --help


Usage
=====

Computational Experiments
-------------------------

It is possible to list, show and execute all the computational experiments using a command line interface
(CLI).

All the available experiments can be listed like this:

.. code-block:: shell

    python3 -m megan_global_explanations.cli list

The details for a specific experiment can be viewed like this:

.. code-block:: shell

    python3 -m megan_global_explanations.cli info [experiment_name]

A new run of an experiment can be started like this.

.. code-block::

    python3 -m megan_global_explanations.cli run [experiment_name]

Be aware that the execution of any experiment will most likely take a lot of time.

Each experiment will create a new archive folder, which will contain all the artifacts (such as visual
examples and the raw data) created during the runtime. The location of this archive folder can be found
from the output generated by the experiment execution.

Archived Experiments
--------------------

To view the detailed data which was used in the making of the paper, go to
``megan_global_explanations/experiments``. The subfolders in that folder contain the archived experiments.
These contain extensive examples for each repetition of the various experiments as well as all of the raw
data collected during the execution of the experiments.


Credits
=======

* PyComex_ is a micro framework which simplifies the setup, processing and management of computational
  experiments. It is also used to auto-generate the command line interface that can be used to interact
  with these experiments.

.. _PyComex: https://github.com/the16thpythonist/pycomex.git
.. _MEGAN: https://link.springer.com/chapter/10.1007/978-3-031-44067-0_18 