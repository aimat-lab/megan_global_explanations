import os
import base64
import typing as t

import requests


def encode_image(image_path: str) -> str:
    """
    Encodes the given image with the given ``image_path`` as a base64 string.
    
    This is mainly required for the GPT-4-Vision API because the only way to pass custom local images to it 
    is by first encoding them as a string and then sending that string as part of the POST payload.
    
    :param image_path: The absolute string path to the image that should be encoded.
    
    :return: The base64 encoded string of the image.
    """
    with open(image_path, 'rb') as f:
        image_data = f.read()
    return base64.b64encode(image_data).decode('utf-8')


def describe_color_graph(api_key: str,
                         image_path: str,
                         max_tokens: int = 200,
                         ) -> tuple[str, list[dict]]:
    """
    Given an OpenAI ``api_key`` and an image ``image_path`` this function will generate a description 
    of the color graph that is depicted in the given image.
    
    This function queries OpenAI's GPT-4-Vision API to generate the description.
    
    :param api_key: The OpenAI API key that should be used for the query.
    :param image_path: The absolute string path to the image that should be described.
    :param max_tokens: The maximum number of tokens that should be generated by the GPT assistant.
    
    :returns: A tuple of the description string and the list of messages that were exchanged during the
        query process, which includes not only the initial user messages but also the assistants response
        messages.
    """
    
    system_message = (
        'You are an assistant helping in data interpretation. Your task is to accurately describe images of color graphs. '
        'These are graph structures whose nodes are colored in different colors. Certain structural motifs of these graphs are '
        'connected to certain properties of the underlying data. Your task is to describe the structure of the graph in '
        'order to better understand the underlying task. Only provide a description of the graph structure and no interpretation. '
        'there is also no need to describe the edges of the graph.'
    )
    
    user_message = (
        'Please describe the color graph structure in the given image. Please first provide a short summarizing description of '
        'the structure as a whole, such as "a branching mostly-yellow graph with green nodes",'
        '"a star-shaped magenta graph with a white node in the middle" or "a mostly-blue triangular pattern with some green nodes"'
        'Please start this first sentence with the phrase "you are looiking at [summary]" \n\n'
        'Afterwards, please describe the graph in more detail by describing the individual patterns and structures that can be found '
        'in it.'
    )
    
    # The query_gpt function will take care of the actual query process and return the description string as well as the
    # list of messages that were exchanged during the query process.
    description, messages = query_gpt(
        api_key=api_key,
        system_message=system_message,
        user_message=user_message,
        image_paths=[image_path],
    )
    
    return description, messages


def describe_molecule(api_key: str,
                      smiles: str,
                      image_path: t.Optional[str] = None,
                      max_tokens: int = 500,
                      ) -> tuple[str, list[dict]]:
    """
    Given an OpenAI ``api_key`` and a SMILES string ``smiles`` this function will generate a description 
    of the molecule that is represented by the given SMILES string. Optionally an ``image_path`` of the molecule 
    can also be given as an input. In this case the description will be generated based on the given image
    in addition to the SMILES string.
    
    This function queries OpenAI's GPT-4-Vision API to generate the description.
    
    :param api_key: The OpenAI API key that should be used for the query.
    :param smiles: The SMILES string representation of the molecule that should be described.
    :param image_path: An optional absolute string path to an image of the molecule that should be described.
    
    :returns: A tuple of the description string and the list of messages that were exchanged during the
        query process, which includes not only the initial user messages but also the assistants response 
        messages.
    """
    
    system_message = (
        f'You are a chemistry expert tasked with describing molecular structures. In this context it is possible to occasionally '
        f'encounter molecular fragements as well - meaning incomplete molecular structures.\n'
        f'Your task is to describe the molecular structures that are presented to you in SMILES representation in natural language.\n'
        f'you should start your description with a summarizing name or brief description of the structure, '
        f'starting with the phrase "the graph represents [summary]"\n'
        f'After that please describe the structure in more detail.'
    )
    
    image_paths = []
    #if image_path is None:
    if True:
        # user_message = (
        #     f'Please describe the molecule that is given as the SMILES structure {smiles} \n'
        #     f'Start your description by providing a name of a brief summarizing description of the molecule '
        #     f'as a whole and then continue by describing its structure in more detail.'
        # )
        user_message = (
            f'Please describe the following molecule with the given SMILES representation: "{smiles}"'
        )

    else:
        user_message = (
            f'Please describe the molecule that is given as the SMILES structure {smiles} \n'
            f'and is depicted in the given image.'
            f'Start your description by providing a name of a brief summarizing description of the molecule '
            f'as a whole and then continue by describing its structure in more detail.'
        )
        image_paths.append(image_path)
    
    # The query_gpt function will take care of the actual query process and return the description string as well as the
    # list of messages that were exchanged during the query process.
    content, messages = query_gpt(
        api_key=api_key,
        system_message=system_message,
        user_message=user_message,
        image_paths=image_paths,
    )
    
    return content, messages


def query_gpt(api_key: str,
              system_message: str,
              user_message: str,
              image_paths: list[str] = [],
              max_tokens: int = 500,
              message_history: list[dict] = [],
              # Only this specific vision model is also able to process images as part of the query input.
              model: str = 'gpt-4-vision-preview',
              ) -> tuple[str, list[dict]]:
    """
    This function queries the OpenAI GPT chat completion API using the given ``system_message`` and ``user_message``.
    Optionally it is possible to provide a number of ``image_paths`` which will be sent to the model as part of the 
    user message as well.
    
    :param api_key: The OpenAI API key that should be used for the query.
    :param system_message: The message that should be sent to the system role.
    :param user_message: The message that should be sent to the user role.
    :param image_paths: A list of absolute string paths to images that should be sent to the user role as well.
    :param max_tokens: The maximum number of tokens that should be generated by the GPT assistant.
    :param message_history: A list of messages that have already been exchanged between the system and the user.
    :param model: The model that should be used for the query. The default is the "gpt-4-vision-preview" model
        which is the only model that is able to process images as part of the query input.
    
    :returns: A tuple of the description string and the list of messages that were exchanged during the
        query process, which includes not only the initial user messages but also the assistants response
        messages.
    """
    user_content = [
        {
            'type': 'text',
            'text': user_message,
        }
    ]
    # Additionally to the pure text message, it is also possible to pass multiple image objects as part of the
    # user message. This is done by encoding the image as a base64 string and then passing it as a data url.
    # So if additional images have been passed as arguments they are sent as part of the user query.
    for image_path in image_paths:
        user_content.append({
            'type': 'image_url',
            'image_url': f'data:image/png;base64,{encode_image(image_path)}',
        })
    
    messages = [
        {
            'role': 'system',
            'content': [{'type': 'text', 'text': system_message}]
        },
        *message_history,
        {  
            'role': 'user',
            'content': user_content,
        }
    ]
    
    headers = {
        'Content-Type': 'application/json',
        'Authorization': f'Bearer {api_key}'
    }
    payload = {
        'model': model,
        'messages': messages,
        'max_tokens': max_tokens,
    }
    response = requests.post('https://api.openai.com/v1/chat/completions', headers=headers, json=payload)
    data = response.json()
    
    # The response data would only contain the "error" field in case something went wrong with the query.
    if 'error' in data:
        raise RuntimeError('GPT Query Error:' + str(data['error']))
    
    # The return content is structured as json content and this is how we get the actual message dict that the 
    # gpt assistant role has generated.
    message: dict = data['choices'][0]
    # We add this message to the list of already existing (user) messages because this chat history might need 
    # to get reused in the future for the hypothesis prediction for example.
    messages.append(message)
    
    content: str = message['message']['content']
    
    return content, messages
